{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image captioning problem.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOgPdpYgOjtH7VN6qzU9ld5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ralfcam/Machine-Learning/blob/master/Image_captioning_problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvJsiKKaumNg",
        "colab_type": "text"
      },
      "source": [
        "# Image captioning problem\n",
        "\n",
        "---\n",
        "\n",
        "[Challenge Details](https://competitions.codalab.org/competitions/25195?secret_key=5ade52a5-0232-4034-85af-c28c39c928ba#learn_the_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bys48_VOu17Q",
        "colab_type": "text"
      },
      "source": [
        "## Imports\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBVuXy3_NnoW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7fc0034-12b1-4ac0-8c2f-a02dc55d8b14"
      },
      "source": [
        "!pip install tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSW7TRkgthhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import requests\n",
        "import queue\n",
        "import threading\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(7053)\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgSVaqHlu6cH",
        "colab_type": "text"
      },
      "source": [
        "## Get Data\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "[Downloading files with wget](https://www.gnu.org/software/wget/manual/wget.html#Download-Options)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovQxD1vv1Np6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a71597e3-0bae-4256-f6e0-2c58f776369f"
      },
      "source": [
        "!wget -O images.zip -b \"http://images.cocodataset.org/zips/train2014.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-19 13:47:15--  http://images.cocodataset.org/zips/train2014.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.45.108\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.45.108|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13510573713 (13G) [application/zip]\n",
            "Saving to: ‘images.zip’\n",
            "\n",
            "images.zip          100%[===================>]  12.58G  16.5MB/s    in 13m 48s \n",
            "\n",
            "2020-06-19 14:01:04 (15.6 MB/s) - ‘images.zip’ saved [13510573713/13510573713]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD6PtMpZ1sLj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "43854817-0bcf-4930-d350-a37e6d1b3a29"
      },
      "source": [
        "!wget -O annotations.zip -b \"http://images.cocodataset.org/annotations/annotations_trainval2014.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-19 14:01:07--  http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.98.139\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.98.139|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252872794 (241M) [application/zip]\n",
            "Saving to: ‘annotations.zip’\n",
            "\n",
            "annotations.zip     100%[===================>] 241.16M  16.7MB/s    in 16s     \n",
            "\n",
            "2020-06-19 14:01:23 (15.0 MB/s) - ‘annotations.zip’ saved [252872794/252872794]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1pKCjugJlpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_path = \"images.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oEOqDzauHrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample images for learners\n",
        "def sample_zip(fn_in, fn_out, rate=0.001):\n",
        "  with ZipFile(fn_in) as fin, ZipFile(fn_out, \"w\") as fout:\n",
        "      sampled = filter(lambda _: np.random.rand() < rate, fin.filelist)\n",
        "      for zInfo in sampled:\n",
        "          fout.writestr(zInfo, fin.read(zInfo))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlRjNvPDtPNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_zip(images_path, \"images_samples.zip\")\n",
        "# sample_zip(\"val2014.zip\", \"val2014_sample.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2imNdiJO-3M5",
        "colab_type": "text"
      },
      "source": [
        "## Model Encoder\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYM1Arby8SSn",
        "colab_type": "text"
      },
      "source": [
        "### Pre-trained InceptionV3 Model for CNN encoder\n",
        "\n",
        "[![Pre-trained InceptionV3 Model for CNN encoder](https://4.bp.blogspot.com/-TMOLlkJBxms/Vt3HQXpE2cI/AAAAAAAAA8E/7X7XRFOY6Xo/s1600/image03.png)](https://ai.googleblog.com/2016/03/train-your-own-image-classifier-with.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY1p5HWd8RxH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9bf762a5-6a46-4049-ded7-8b6a798fbf4e"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5_Sjxea_Rau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we take the last hidden layer of IncetionV3 as an image embedding\n",
        "\n",
        "tf.keras.backend.set_learning_phase(False)\n",
        "\n",
        "model_ = tf.keras.applications.InceptionV3(\n",
        "    include_top=False, weights='imagenet', input_tensor=None, input_shape=None,\n",
        "    pooling=None, classes=1000, classifier_activation='softmax'\n",
        "    )\n",
        "\n",
        "model_inputs = model_.inputs\n",
        "model_output = model_.output\n",
        "\n",
        "preprocess_for_model = tf.keras.applications.inception_v3.preprocess_input\n",
        "\n",
        "cnn_encoder = tf.keras.Model(\n",
        "    model_inputs,\n",
        "    tf.keras.layers.GlobalAveragePooling2D()(model_output)\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw7hBXo1HAeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cnn_encoder.get_config()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXLNzzPYIkuI",
        "colab_type": "text"
      },
      "source": [
        "### Extract train features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbafwoXOSejZ",
        "colab_type": "text"
      },
      "source": [
        "### Util Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEeo0aGNLhxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def apply_model(zip_fn, model, preprocess_for_model, extensions=(\".jpg\",),\n",
        "                input_shape=(224, 224), batch_size=32):\n",
        "    # queue for cropped images\n",
        "    q = queue.Queue(maxsize=batch_size * 10)\n",
        "\n",
        "    # when read thread put all images in queue\n",
        "    read_thread_completed = threading.Event()\n",
        "\n",
        "    # time for read thread to die\n",
        "    kill_read_thread = threading.Event()\n",
        "\n",
        "    def reading_thread(zip_fn):\n",
        "        zf = ZipFile(zip_fn)\n",
        "        for fn in zf.namelist():\n",
        "            if kill_read_thread.is_set():\n",
        "                break\n",
        "            if os.path.splitext(fn)[-1] in extensions:\n",
        "                buf = zf.read(fn)  # read raw bytes from zip for fn\n",
        "                img = decode_image_from_buf(buf)  # decode raw bytes\n",
        "                img = crop_and_preprocess(img, input_shape, preprocess_for_model)\n",
        "                while True:\n",
        "                    try:\n",
        "                        q.put((os.path.split(fn)[-1], img), timeout=1)  # put in queue\n",
        "                    except queue.Full:\n",
        "                        if kill_read_thread.is_set():\n",
        "                            break\n",
        "                        continue\n",
        "                    break\n",
        "\n",
        "        read_thread_completed.set()  # read all images\n",
        "\n",
        "    # start reading thread\n",
        "    t = threading.Thread(target=reading_thread, args=(zip_fn,))\n",
        "    t.daemon = True\n",
        "    t.start()\n",
        "\n",
        "    img_fns = []\n",
        "    img_embeddings = []\n",
        "\n",
        "    batch_imgs = []\n",
        "\n",
        "    def process_batch(batch_imgs):\n",
        "        batch_imgs = np.stack(batch_imgs, axis=0)\n",
        "        batch_embeddings = model.predict(batch_imgs)\n",
        "        img_embeddings.append(batch_embeddings)\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            try:\n",
        "                fn, img = q.get(timeout=1)\n",
        "            except queue.Empty:\n",
        "                if read_thread_completed.is_set():\n",
        "                    break\n",
        "                continue\n",
        "            img_fns.append(fn)\n",
        "            batch_imgs.append(img)\n",
        "            if len(batch_imgs) == batch_size:\n",
        "                process_batch(batch_imgs)\n",
        "                batch_imgs = []\n",
        "            q.task_done()\n",
        "        # process last batch\n",
        "        if len(batch_imgs):\n",
        "            process_batch(batch_imgs)\n",
        "    finally:\n",
        "        kill_read_thread.set()\n",
        "        t.join()\n",
        "\n",
        "    q.join()\n",
        "\n",
        "    img_embeddings = np.vstack(img_embeddings)\n",
        "    return img_embeddings, img_fns\n",
        "\n",
        "\n",
        "def save_pickle(obj, fn):\n",
        "    with open(fn, \"wb\") as f:\n",
        "        pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "def decode_image_from_buf(buf):\n",
        "    img = cv2.imdecode(np.asarray(bytearray(buf), dtype=np.uint8), 1)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img\n",
        "\n",
        "\n",
        "def crop_and_preprocess(img, input_shape, preprocess_for_model):\n",
        "    img = image_center_crop(img)  # take center crop\n",
        "    img = cv2.resize(img, input_shape)  # resize for our model\n",
        "    img = img.astype(\"float32\")  # prepare for normalization\n",
        "    img = preprocess_for_model(img)  # preprocess for model\n",
        "    return img\n",
        "\n",
        "\n",
        "def image_center_crop(img):\n",
        "    h, w = img.shape[0], img.shape[1]\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    if h > w:\n",
        "        diff = h - w\n",
        "        pad_top = diff - diff // 2\n",
        "        pad_bottom = diff // 2\n",
        "    else:\n",
        "        diff = w - h\n",
        "        pad_left = diff - diff // 2\n",
        "        pad_right = diff // 2\n",
        "    return img[pad_top:h-pad_bottom, pad_left:w-pad_right, :]\n",
        "\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M2zKPMsSuIh",
        "colab_type": "text"
      },
      "source": [
        "### Fit Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT5-6-IRHKDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 299\n",
        "train_img_embeds, train_img_fns = apply_model(\n",
        "    images_path, cnn_encoder, preprocess_for_model, \n",
        "    input_shape=(IMG_SIZE, IMG_SIZE)\n",
        "    )\n",
        "\n",
        "save_pickle(train_img_embeds, \"train_img_embeds.pickle\")\n",
        "save_pickle(train_img_fns, \"train_img_fns.pickle\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}